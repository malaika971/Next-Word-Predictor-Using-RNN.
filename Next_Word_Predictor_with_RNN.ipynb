{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6cad88ca-af4e-4163-9c26-4e207454f2ef",
      "metadata": {
        "id": "6cad88ca-af4e-4163-9c26-4e207454f2ef"
      },
      "source": [
        "# ***Next Word Predictor Using RNN***\n",
        "\n",
        "\n",
        "***Objective:*** Building a simple application using RNNs predicting the next word in a sentence of a paragraph.\n",
        "***\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e5f28b3-7f2f-4f1a-b3f2-4d9b853c9167",
      "metadata": {
        "id": "9e5f28b3-7f2f-4f1a-b3f2-4d9b853c9167"
      },
      "source": [
        "\n",
        " # <span style='color:Red'>  ***Recurrent Neural Networks*** </span>\n",
        "\n",
        "- Recurrent Neural Networks (RNN) are designed to work with sequential data. Sequential data(can be time-series) can be in form of text, audio, video etc.\n",
        "\n",
        "- RNN uses the previous information in the sequence to produce the current output. To understand this better take an example sentence.\n",
        "\n",
        "                                      “My class is the best class.”\n",
        "\n",
        "- At the time(T0 ), the first step is to feed the word “My” into the network. the RNN produces an output.\n",
        "\n",
        "- At the time(T1 ), then at the next step we feed the word “class” and the activation value from the previous step. Now the RNN has information of both words “My” and “class”.\n",
        "\n",
        "- RNN takes the output from the previous step as an input to the next step. It can retain information from the past and use that information to process new input."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc7e6302-bf53-4143-9eee-fac4d4224cab",
      "metadata": {
        "id": "cc7e6302-bf53-4143-9eee-fac4d4224cab"
      },
      "source": [
        "![image.png](attachment:89551eab-1e5f-46f4-b231-de61cfe6df45.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52f09208-85f0-4689-8eaa-e8c3b3f383cd",
      "metadata": {
        "id": "52f09208-85f0-4689-8eaa-e8c3b3f383cd"
      },
      "source": [
        "***\n",
        "\n",
        " ## <span style='color:Blue'>  ***Types of RNN*** </span>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "![image.png](attachment:dbcae600-3e87-4701-8beb-cd5af1d4fb2b.png)\n",
        "\n",
        "\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "256831ae-ec2c-47da-a8e8-70baa295a21e",
      "metadata": {
        "id": "256831ae-ec2c-47da-a8e8-70baa295a21e"
      },
      "source": [
        "\n",
        " ## <span style='color:Blue'>  ***Long Short-Term Memory (LSTM)*** </span>\n",
        "\n",
        "-\n",
        "LSTMs come to the rescue to solve the vanishing gradient problem. It does so by ignoring (forgetting) useless data/information in the network\n",
        "-  The LSTM will forget the data if there is no useful information from other inputs (prior sentence words). When new information comes, the network determines which information to be overlooked and which to be remembered\n",
        "\n",
        "- In LSTMs, instead of just a simple network with a single activation function, we have multiple components, giving power to the network to forget and remember information.\n",
        "\n",
        "![image.png](attachment:0a8d206f-18ae-4508-8f92-6bd0239c85ce.png)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23c51e5d-dfdb-4844-bcbb-9da72cb3e7ff",
      "metadata": {
        "id": "23c51e5d-dfdb-4844-bcbb-9da72cb3e7ff"
      },
      "source": [
        "***\n",
        "# ***LSTMs have 3 different components, namely***\n",
        "\n",
        "- Forget gate\n",
        "- Input gate\n",
        "- Output gate\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76cb24ae-a18a-491b-a0ba-ecc1e37e9989",
      "metadata": {
        "id": "76cb24ae-a18a-491b-a0ba-ecc1e37e9989"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "![image.png](attachment:8856c324-64fb-47ef-bf29-fc450af3d036.png)\n",
        "\n",
        "\n",
        "gate\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14512835-9375-44e8-9aaa-c5472317384d",
      "metadata": {
        "id": "14512835-9375-44e8-9aaa-c5472317384d"
      },
      "source": [
        "***\n",
        "\n",
        "##  ***Forget Gate***\n",
        "- The forget LSTM gate, as the name suggests, decides what information should be forgotten. A sigmoid layer is used to make this decision. This sigmoid layer is called the “forget gate layer”.\n",
        "\n",
        "\n",
        "![image.png](attachment:27d8490e-8f61-4349-aa8c-0ff4e84a73a3.png)\n",
        "\n",
        "\n",
        "\n",
        "- It does a dot product of h(t-1) and x(t) and with the help of the sigmoid layer, outputs a number between 0 and 1 for each number in the cell state C(t-1). If the output is a ‘1’, it means we will keep it. A ‘0’ means to forget it completely.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ed3a7da-ac62-4efb-930f-ce3ab867917e",
      "metadata": {
        "id": "6ed3a7da-ac62-4efb-930f-ce3ab867917e"
      },
      "source": [
        "## ***Input gate***\n",
        "- The input gate gives new information to the LSTM and decides if that new information is going to be stored in the cell state.\n",
        "\n",
        "![image.png](attachment:c138580d-8540-4d9d-83f7-c7f8e80952c0.png)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ate."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bfecb1d-0309-46bf-a74d-aa616dde9bf8",
      "metadata": {
        "id": "2bfecb1d-0309-46bf-a74d-aa616dde9bf8"
      },
      "source": [
        "This has 3 parts:\n",
        "\n",
        "- A sigmoid layer decides the values to be updated. This layer is called the “input gate layer”\n",
        "- A tanh activation function layer creates a vector of new candidate values, Č(t), that could be added to the state.\n",
        "- Then we combine these 2 outputs, i(t) * Č(t), and update the cell state."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e31effe-9b65-42f4-b1ed-52fbb7fb82ab",
      "metadata": {
        "id": "2e31effe-9b65-42f4-b1ed-52fbb7fb82ab"
      },
      "source": [
        "## ***Output gate***\n",
        "-\n",
        "The output of the LSTM unit depends on the new cell state\n",
        "\n",
        "\n",
        "- First, a sigmoid layer decides what parts of the cell state we’re going to output.\n",
        "- Then, a tanh layer is used on the cell state to squash the values between -1 and 1, which is finally multiplied by the sigmoid gate output.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "![image.png](attachment:d502e38f-374f-4a56-9d30-454f4c1bc140.png)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6914ba91-4802-4c98-946f-e84945ebdd30",
      "metadata": {
        "id": "6914ba91-4802-4c98-946f-e84945ebdd30"
      },
      "source": [
        "***\n",
        " ## <span style='color:Blue'>  ***LSTM in Action*** </span>\n",
        "\n",
        "![0_O_TqfQ4537oM4MH0.gif](attachment:aa18c922-c984-4b79-9f6f-de411e792694.gif)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e868a12-01f9-49ef-8c50-6d37c5ad6ecd",
      "metadata": {
        "id": "8e868a12-01f9-49ef-8c50-6d37c5ad6ecd"
      },
      "source": [
        "***\n",
        "\n",
        "\n",
        " # <span style='color:Red'>  ***Building Next Word Predictor in a Sentence Using RNN*** </span>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0f6e8019-6c6d-4b18-8b0b-5e4def9f76c9",
      "metadata": {
        "id": "0f6e8019-6c6d-4b18-8b0b-5e4def9f76c9"
      },
      "outputs": [],
      "source": [
        "text = \"\"\" It was November. Although it was not yet late.\n",
        "the sky was dark when I turned into Laundress Passage. Father had finished for the day.\n",
        "switched off the shop lights and closed the shutters.\n",
        "but so I would not come home to darkness he had left on the light over the stairs to the flat.\n",
        "Through the glass in the door it cast a foolscap rectangle of paleness onto the wet pavement.\n",
        "and it was while I was standing in that rectangle. about to turn my key in the door. that I first saw the letter \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c092d38f-b484-4325-8a34-bcb5c0f49fb0",
      "metadata": {
        "id": "c092d38f-b484-4325-8a34-bcb5c0f49fb0"
      },
      "source": [
        "## ***Importing Libraries***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "fd0fefe9-87b7-4f5d-8c59-3bccc446936d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd0fefe9-87b7-4f5d-8c59-3bccc446936d",
        "outputId": "bee92a9a-6432-4844-a281-42fbbb64ab73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5.05 s, sys: 636 ms, total: 5.69 s\n",
            "Wall time: 9.16 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "import numpy as np\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5bb4870-fb7f-4e6c-96e6-8065cca91b5f",
      "metadata": {
        "id": "f5bb4870-fb7f-4e6c-96e6-8065cca91b5f"
      },
      "source": [
        "# ***Tokenization***\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "bbc7fc36-c8db-4ea7-be60-c0eb845f8500",
      "metadata": {
        "id": "bbc7fc36-c8db-4ea7-be60-c0eb845f8500"
      },
      "outputs": [],
      "source": [
        "# Tokenization\n",
        "# Initializing the Tokenizer to convert text into sequences of integers\n",
        "tokenizer = Tokenizer()\n",
        "# Fitting the tokenizer on the text\n",
        "tokenizer.fit_on_texts([text])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1acedc44-235a-4ed4-bbec-237a1bd394a2",
      "metadata": {
        "id": "1acedc44-235a-4ed4-bbec-237a1bd394a2"
      },
      "outputs": [],
      "source": [
        "# Preparing input sequences for training\n",
        "input_sequences = []\n",
        "# Splitting the text into sentences based on new lines\n",
        "for sentence in text.split('\\n'):\n",
        "    # Converting each sentence into a sequence of integers\n",
        "    tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
        "    # Creating sub-sequences for training\n",
        "    # For each sentence, generate sequences that progressively grow in length\n",
        "    for i in range(1, len(tokenized_sentence)):\n",
        "        input_sequences.append(tokenized_sentence[:i+1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "793374cd-f03c-4ca6-8ed8-91447dc66b77",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "793374cd-f03c-4ca6-8ed8-91447dc66b77",
        "outputId": "f20d9f7e-4490-4886-ba72-a827fc182512"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Finding the maximum sequence length to ensure all sequences have the same length\n",
        "max_len = max([len(x) for x in input_sequences])\n",
        "\n",
        "max_len"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3172a28e-aa37-4866-a434-cc78b59f8aed",
      "metadata": {
        "id": "3172a28e-aa37-4866-a434-cc78b59f8aed"
      },
      "source": [
        "## ***Applying Padding Sequences***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d620b2b8-fc65-4013-8be6-9527ab7d8f8f",
      "metadata": {
        "id": "d620b2b8-fc65-4013-8be6-9527ab7d8f8f"
      },
      "outputs": [],
      "source": [
        "# Padding sequences\n",
        "# Padding all sequences to the same length with zeros at the beginning (pre-padding)\n",
        "padded_input_sequences = pad_sequences(input_sequences, maxlen=max_len, padding='pre')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f49b797b-fdb8-4b2e-a16e-b8f1bec6c1fc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f49b797b-fdb8-4b2e-a16e-b8f1bec6c1fc",
        "outputId": "62d8f3c7-d4c0-4ad0-e924-97f2d0aceb34"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ...,  0,  3,  2],\n",
              "       [ 0,  0,  0, ...,  3,  2, 13],\n",
              "       [ 0,  0,  0, ...,  2, 13, 14],\n",
              "       ...,\n",
              "       [ 0,  0,  9, ...,  4, 63, 64],\n",
              "       [ 0,  9,  3, ..., 63, 64,  1],\n",
              "       [ 9,  3,  2, ..., 64,  1, 65]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "padded_input_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bec30c12-6258-474e-b05d-3ed20d6e6a91",
      "metadata": {
        "id": "bec30c12-6258-474e-b05d-3ed20d6e6a91"
      },
      "source": [
        "## ***Defining X and y for training***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "7ff9377c-9efb-4dd9-a661-70e2eb256677",
      "metadata": {
        "id": "7ff9377c-9efb-4dd9-a661-70e2eb256677"
      },
      "outputs": [],
      "source": [
        "# X is the input sequence up to the second-to-last word\n",
        "X = padded_input_sequences[:, :-1]\n",
        "# y is the last word of each sequence, which we aim to predict\n",
        "y = padded_input_sequences[:, -1]\n",
        "# Converting y into categorical (one-hot encoded) format with dimensions equal to the vocabulary size\n",
        "y = to_categorical(y, num_classes=len(tokenizer.word_index) + 1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56649546-2c26-4fde-a0e0-c981aa3fa809",
      "metadata": {
        "id": "56649546-2c26-4fde-a0e0-c981aa3fa809"
      },
      "source": [
        "## ***Building the Sequential RNN model***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c83c38ac-f795-46e6-af71-8bdc7877aff6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c83c38ac-f795-46e6-af71-8bdc7877aff6",
        "outputId": "8c71c454-e51e-4bcd-ffd7-b4feaac6dd47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Adding an Embedding layer\n",
        "# The Embedding layer maps each word to a dense vector of fixed size (100 in this case)\n",
        "# Input dimension is the size of the vocabulary (number of unique words + 1)\n",
        "model.add(Embedding(len(tokenizer.word_index) + 1, 100, input_length=max_len - 1))\n",
        "\n",
        "# Adding the first LSTM layer\n",
        "# LSTM layer with 150 units, set to return sequences to feed into the next LSTM layer\n",
        "model.add(LSTM(150, return_sequences=True))\n",
        "\n",
        "# Adding a second LSTM layer\n",
        "# This LSTM does not return sequences, it outputs a single vector representing the entire sequence\n",
        "model.add(LSTM(150))\n",
        "\n",
        "# Adding a Dense output layer\n",
        "# This layer outputs a probability distribution over the vocabulary, with softmax activation\n",
        "model.add(Dense(len(tokenizer.word_index) + 1, activation='softmax'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6695bc8-506f-4fae-8b52-ef3bd9be959a",
      "metadata": {
        "id": "c6695bc8-506f-4fae-8b52-ef3bd9be959a"
      },
      "source": [
        "## ***Compiling the model***\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a6e163ef-2a68-431d-9459-ca938b05fa78",
      "metadata": {
        "id": "a6e163ef-2a68-431d-9459-ca938b05fa78"
      },
      "outputs": [],
      "source": [
        "# Using categorical crossentropy as the loss function and Adam optimizer\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "342457ef-572f-47e1-b6c4-8f5437c77205",
      "metadata": {
        "id": "342457ef-572f-47e1-b6c4-8f5437c77205"
      },
      "source": [
        "## ***Training the model***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7554e18f-9896-44f2-8196-3ab845c74d5c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7554e18f-9896-44f2-8196-3ab845c74d5c",
        "outputId": "dc73c369-9895-4934-cb2f-d8680fb68a82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.0261 - loss: 4.1882\n",
            "Epoch 2/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.1158 - loss: 4.1513\n",
            "Epoch 3/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.1549 - loss: 4.0365\n",
            "Epoch 4/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1275 - loss: 3.9104\n",
            "Epoch 5/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.1353 - loss: 3.9346\n",
            "Epoch 6/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.1353 - loss: 3.8506\n",
            "Epoch 7/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.1141 - loss: 3.8767\n",
            "Epoch 8/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.1236 - loss: 3.8105\n",
            "Epoch 9/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.1275 - loss: 3.7651\n",
            "Epoch 10/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.1370 - loss: 3.6986\n",
            "Epoch 11/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.1543 - loss: 3.6428\n",
            "Epoch 12/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.1621 - loss: 3.6115\n",
            "Epoch 13/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.1174 - loss: 3.5946\n",
            "Epoch 14/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.1464 - loss: 3.4918\n",
            "Epoch 15/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.1464 - loss: 3.4513\n",
            "Epoch 16/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.1464 - loss: 3.3471\n",
            "Epoch 17/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.1448 - loss: 3.2844\n",
            "Epoch 18/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.1660 - loss: 3.1981\n",
            "Epoch 19/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.1715 - loss: 3.1067\n",
            "Epoch 20/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.2155 - loss: 3.0915\n",
            "Epoch 21/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.1944 - loss: 3.0294\n",
            "Epoch 22/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.1927 - loss: 2.9072\n",
            "Epoch 23/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 205ms/step - accuracy: 0.1497 - loss: 3.0160\n",
            "Epoch 24/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 187ms/step - accuracy: 0.1670 - loss: 2.9196\n",
            "Epoch 25/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 184ms/step - accuracy: 0.1804 - loss: 2.8846\n",
            "Epoch 26/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 173ms/step - accuracy: 0.1670 - loss: 2.8681\n",
            "Epoch 27/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 172ms/step - accuracy: 0.2110 - loss: 2.7746\n",
            "Epoch 28/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 185ms/step - accuracy: 0.1804 - loss: 2.7163\n",
            "Epoch 29/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step - accuracy: 0.1787 - loss: 2.6898\n",
            "Epoch 30/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 179ms/step - accuracy: 0.2038 - loss: 2.6230\n",
            "Epoch 31/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 173ms/step - accuracy: 0.2166 - loss: 2.6273\n",
            "Epoch 32/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 164ms/step - accuracy: 0.2394 - loss: 2.5179\n",
            "Epoch 33/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 217ms/step - accuracy: 0.2495 - loss: 2.5076\n",
            "Epoch 34/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 160ms/step - accuracy: 0.2511 - loss: 2.4435\n",
            "Epoch 35/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 171ms/step - accuracy: 0.2466 - loss: 2.4301\n",
            "Epoch 36/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 174ms/step - accuracy: 0.3274 - loss: 2.3394\n",
            "Epoch 37/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 182ms/step - accuracy: 0.2812 - loss: 2.3117\n",
            "Epoch 38/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 182ms/step - accuracy: 0.3949 - loss: 2.2354\n",
            "Epoch 39/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 167ms/step - accuracy: 0.3893 - loss: 2.1954\n",
            "Epoch 40/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 166ms/step - accuracy: 0.4165 - loss: 2.1510\n",
            "Epoch 41/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 166ms/step - accuracy: 0.4967 - loss: 2.1105\n",
            "Epoch 42/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 192ms/step - accuracy: 0.4638 - loss: 2.0807\n",
            "Epoch 43/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 154ms/step - accuracy: 0.4928 - loss: 2.0323\n",
            "Epoch 44/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5167 - loss: 1.9662\n",
            "Epoch 45/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.5418 - loss: 1.9186\n",
            "Epoch 46/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 168ms/step - accuracy: 0.4710 - loss: 1.9037\n",
            "Epoch 47/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 164ms/step - accuracy: 0.5368 - loss: 1.8360\n",
            "Epoch 48/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 164ms/step - accuracy: 0.5496 - loss: 1.8820\n",
            "Epoch 49/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 168ms/step - accuracy: 0.4426 - loss: 1.8588\n",
            "Epoch 50/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 204ms/step - accuracy: 0.5786 - loss: 1.7583\n",
            "Epoch 51/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 178ms/step - accuracy: 0.6353 - loss: 1.7070\n",
            "Epoch 52/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 157ms/step - accuracy: 0.5891 - loss: 1.7199\n",
            "Epoch 53/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 166ms/step - accuracy: 0.5707 - loss: 1.6348\n",
            "Epoch 54/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 162ms/step - accuracy: 0.5874 - loss: 1.6366\n",
            "Epoch 55/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 183ms/step - accuracy: 0.5940 - loss: 1.6389\n",
            "Epoch 56/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 171ms/step - accuracy: 0.7022 - loss: 1.5194\n",
            "Epoch 57/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - accuracy: 0.7188 - loss: 1.5116\n",
            "Epoch 58/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7266 - loss: 1.3916\n",
            "Epoch 59/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7433 - loss: 1.3985\n",
            "Epoch 60/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7511 - loss: 1.3419\n",
            "Epoch 61/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.7355 - loss: 1.3461\n",
            "Epoch 62/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.7489 - loss: 1.3453\n",
            "Epoch 63/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.7740 - loss: 1.2456\n",
            "Epoch 64/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - accuracy: 0.7561 - loss: 1.2755\n",
            "Epoch 65/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.7310 - loss: 1.2981\n",
            "Epoch 66/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.7779 - loss: 1.1821\n",
            "Epoch 67/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 0.7789 - loss: 1.1948\n",
            "Epoch 68/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.7929 - loss: 1.1600\n",
            "Epoch 69/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - accuracy: 0.7912 - loss: 1.0768\n",
            "Epoch 70/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.7655 - loss: 1.1197\n",
            "Epoch 71/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.8147 - loss: 1.0104\n",
            "Epoch 72/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - accuracy: 0.8102 - loss: 0.9998\n",
            "Epoch 73/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.8023 - loss: 1.0353\n",
            "Epoch 74/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 0.7783 - loss: 1.1053\n",
            "Epoch 75/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - accuracy: 0.8118 - loss: 0.9970\n",
            "Epoch 76/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.8408 - loss: 0.9257\n",
            "Epoch 77/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 151ms/step - accuracy: 0.7984 - loss: 0.9778\n",
            "Epoch 78/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - accuracy: 0.6109 - loss: 1.1497\n",
            "Epoch 79/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 157ms/step - accuracy: 0.6843 - loss: 1.1096\n",
            "Epoch 80/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step - accuracy: 0.7199 - loss: 1.0465\n",
            "Epoch 81/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 194ms/step - accuracy: 0.7923 - loss: 0.9789\n",
            "Epoch 82/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 172ms/step - accuracy: 0.7890 - loss: 0.9899\n",
            "Epoch 83/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 156ms/step - accuracy: 0.8023 - loss: 0.9441\n",
            "Epoch 84/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7783 - loss: 0.9695\n",
            "Epoch 85/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.8402 - loss: 0.9112\n",
            "Epoch 86/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.8223 - loss: 0.9107\n",
            "Epoch 87/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.8135 - loss: 0.8894\n",
            "Epoch 88/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.8497 - loss: 0.8545\n",
            "Epoch 89/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.8240 - loss: 0.9135\n",
            "Epoch 90/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.8786 - loss: 0.7663\n",
            "Epoch 91/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.8340 - loss: 0.8905\n",
            "Epoch 92/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.8865 - loss: 0.7584\n",
            "Epoch 93/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.8497 - loss: 0.7794\n",
            "Epoch 94/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.8669 - loss: 0.8087\n",
            "Epoch 95/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.8725 - loss: 0.6944\n",
            "Epoch 96/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9194 - loss: 0.6813\n",
            "Epoch 97/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.8943 - loss: 0.6787\n",
            "Epoch 98/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.8842 - loss: 0.6619\n",
            "Epoch 99/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9054 - loss: 0.6369\n",
            "Epoch 100/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.9060 - loss: 0.5988\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x796b554d2140>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Fitting the model on the prepared data, with X as input and y as output\n",
        "model.fit(X, y, epochs=100, verbose=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d436465-e6f3-4044-9c5d-9db67785c338",
      "metadata": {
        "id": "3d436465-e6f3-4044-9c5d-9db67785c338"
      },
      "source": [
        "## ***Checking Model by chunck of text as input***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ba66895a-57f8-4c15-9083-75b66196b9c7",
      "metadata": {
        "id": "ba66895a-57f8-4c15-9083-75b66196b9c7"
      },
      "outputs": [],
      "source": [
        "# Initial text to start the generation process\n",
        "p_text = \"the sky was dark\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "aa6d2516-8bfa-4610-bbe0-7bace5348350",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa6d2516-8bfa-4610-bbe0-7bace5348350",
        "outputId": "e5dbdfaa-e0fb-4637-8008-b4fb154edd41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step\n",
            "the sky was dark when\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "the sky was dark when i\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "the sky was dark when i turned\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "the sky was dark when i turned into\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "the sky was dark when i turned into laundress\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "the sky was dark when i turned into laundress passage\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "the sky was dark when i turned into laundress passage father\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "the sky was dark when i turned into laundress passage father had\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "the sky was dark when i turned into laundress passage father had finished\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "the sky was dark when i turned into laundress passage father had finished for\n"
          ]
        }
      ],
      "source": [
        "# Loop to generate a sequence of 10 words\n",
        "for i in range(10):\n",
        "    # Tokenize the current text to convert it into a sequence of integers\n",
        "    token_text = tokenizer.texts_to_sequences([p_text])[0]\n",
        "    # Pad the tokenized sequence to the required input length of the model\n",
        "    padded_token_text = pad_sequences([token_text], maxlen=max_len - 1, padding='pre')\n",
        "\n",
        "    # Predict the next word based on the current sequence\n",
        "    pos = np.argmax(model.predict(padded_token_text), axis=-1)[0]\n",
        "\n",
        "    # Find the word corresponding to the predicted index\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == pos:\n",
        "            # Append the predicted word to the text\n",
        "            p_text = p_text + \" \" + word\n",
        "            print(p_text)\n",
        "            # Adding a small delay to slow down the output for better readability\n",
        "            time.sleep(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f70f87b-2aeb-4e71-9938-0e1dc18237b7",
      "metadata": {
        "id": "5f70f87b-2aeb-4e71-9938-0e1dc18237b7"
      },
      "source": [
        "***\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial text to start the generation process\n",
        "p_text = \"Through the glass in the door\""
      ],
      "metadata": {
        "id": "XpyvaShiC2D1"
      },
      "id": "XpyvaShiC2D1",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop to generate a sequence of 10 words\n",
        "for i in range(10):\n",
        "    # Tokenize the current text to convert it into a sequence of integers\n",
        "    token_text = tokenizer.texts_to_sequences([p_text])[0]\n",
        "    # Pad the tokenized sequence to the required input length of the model\n",
        "    padded_token_text = pad_sequences([token_text], maxlen=max_len - 1, padding='pre')\n",
        "\n",
        "    # Predict the next word based on the current sequence\n",
        "    pos = np.argmax(model.predict(padded_token_text), axis=-1)[0]\n",
        "\n",
        "    # Find the word corresponding to the predicted index\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == pos:\n",
        "            # Append the predicted word to the text\n",
        "            p_text = p_text + \" \" + word\n",
        "            print(p_text)\n",
        "            # Adding a small delay to slow down the output for better readability\n",
        "            time.sleep(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ov4Nzz5ECkPY",
        "outputId": "522322ed-2db5-4f18-f6a3-486b47a68549"
      },
      "id": "ov4Nzz5ECkPY",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Through the glass in the door it\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Through the glass in the door it cast\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Through the glass in the door it cast a\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Through the glass in the door it cast a foolscap\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Through the glass in the door it cast a foolscap rectangle\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Through the glass in the door it cast a foolscap rectangle of\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Through the glass in the door it cast a foolscap rectangle of paleness\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Through the glass in the door it cast a foolscap rectangle of paleness onto\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "Through the glass in the door it cast a foolscap rectangle of paleness onto the\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Through the glass in the door it cast a foolscap rectangle of paleness onto the wet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "***"
      ],
      "metadata": {
        "id": "v8kUkMVCEAll"
      },
      "id": "v8kUkMVCEAll"
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial text to start the generation process\n",
        "p_text = \"but so I would not\"\n"
      ],
      "metadata": {
        "id": "pSRC-NRADAFI"
      },
      "id": "pSRC-NRADAFI",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop to generate a sequence of 10 words\n",
        "for i in range(10):\n",
        "    # Tokenize the current text to convert it into a sequence of integers\n",
        "    token_text = tokenizer.texts_to_sequences([p_text])[0]\n",
        "    # Pad the tokenized sequence to the required input length of the model\n",
        "    padded_token_text = pad_sequences([token_text], maxlen=max_len - 1, padding='pre')\n",
        "\n",
        "    # Predict the next word based on the current sequence\n",
        "    pos = np.argmax(model.predict(padded_token_text), axis=-1)[0]\n",
        "\n",
        "    # Find the word corresponding to the predicted index\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == pos:\n",
        "            # Append the predicted word to the text\n",
        "            p_text = p_text + \" \" + word\n",
        "            print(p_text)\n",
        "            # Adding a small delay to slow down the output for better readability\n",
        "            time.sleep(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KY6FPKkbDYAP",
        "outputId": "bf82ad2e-d0ab-4e95-929e-08568c19bda0"
      },
      "id": "KY6FPKkbDYAP",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "but so I would not come\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "but so I would not come home\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "but so I would not come home to\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "but so I would not come home to darkness\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "but so I would not come home to darkness he\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "but so I would not come home to darkness he had\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "but so I would not come home to darkness he had left\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "but so I would not come home to darkness he had left on\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "but so I would not come home to darkness he had left on the\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "but so I would not come home to darkness he had left on the light\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}